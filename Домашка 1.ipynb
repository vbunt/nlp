{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лера Бунтякова, 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import csv\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сбор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я решила использовать сайт с ревью на фильмы - letterboxd.com - и взять с него 90 страниц (80 для составления словаря и 10 для тестов) с отзывами критика Дэвида Эрлиха. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('letterboxd.csv', 'w') as f:\n",
    "    header = ['movie', 'stars', 'review']\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_nothing():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    r = requests.get(url)\n",
    "    r.encoding = 'UTF-8'\n",
    "    return r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_reviews_from_page(url):\n",
    "    page = get_page(url)\n",
    "    soup = BeautifulSoup(page)\n",
    "    page_reviews = soup.find_all('div', {'class':'film-detail-content'})\n",
    "    return page_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    good = []\n",
    "    for token in tokens:\n",
    "        if not token in '.,?!’/<>$%&\"“”\\'-)(_…:;.':\n",
    "            good.append(lemmatizer.lemmatize(token, get_wordnet_pos(token)))\n",
    "    \n",
    "    return ' '.join(good) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_reviews_from_page(page_reviews, writer):\n",
    "    for review in page_reviews:\n",
    "\n",
    "        movie = review.a.string\n",
    "        try:\n",
    "            stars = review.span['class'][2].split('-')[1]\n",
    "        except IndexError:\n",
    "            stars = None\n",
    "        paragraphs = review.find('div', {'class':'body-text -prose collapsible-text'}).find_all('p')\n",
    "        text = ''\n",
    "\n",
    "        if paragraphs:\n",
    "            for paragraph in paragraphs:\n",
    "                try:\n",
    "                    text = text + paragraph.string + ' '\n",
    "                except TypeError:\n",
    "                    do_nothing()\n",
    "        \n",
    "\n",
    "        text = good_text(text.lower())\n",
    "        \n",
    "        \n",
    "        row = [movie, stars, text]\n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a():\n",
    "    with open('letterboxd.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for i in range(1, 80):\n",
    "            url = 'http://letterboxd.com/davidehrlich/films/reviews/page/'+str(i)+'/'\n",
    "            page_reviews = get_all_reviews_from_page(url)\n",
    "            write_reviews_from_page(page_reviews, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание списков слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('letterboxd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Хорошими\" отзывами будут считаться те, где 8 и больше звезд, \"плохими\" - те, где 4 и меньше. Использовать 1 и 10 звезд плохо, потому что тогда будет слишком мало данных, а так получается примерно одинаково много (182 и 213). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how=\"any\")\n",
    "good = df[df['stars']>7]\n",
    "bad = df[df['stars']<5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберем слова из каждого вида отзывов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_words = []\n",
    "for line in good['review']:\n",
    "    good_words.extend(line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words = []\n",
    "for line in bad['review']:\n",
    "    bad_words.extend(line.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И найдем уникальные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_bad_words = set(bad_words)\n",
    "set_good_words = set(good_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_good_words = set_good_words - set_bad_words\n",
    "very_bad_words = set_bad_words - set_good_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй список почти в полтора раза длиннее первого, что приведет к проблемам: при определении тональности один вариант будет перевешивать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(very_good_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2898"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(very_bad_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому возьмем из каждого списка 2000 самых популярных слов и найдем уникальные среди них. Эти списки и будем использовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_good_words = set(w[0] for w in Counter(good_words).most_common(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_bad_words = set(w[0] for w in Counter(bad_words).most_common(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_very_good_words = popular_good_words - popular_bad_words\n",
    "popular_very_bad_words = popular_bad_words - popular_good_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1180"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(popular_very_bad_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1180"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(popular_very_good_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_if_good(review, very_good_words, very_bad_words):\n",
    "    review = good_text(review)\n",
    "    is_good = 0\n",
    "    is_bad = 0\n",
    "    for word in review.split():\n",
    "        if word in very_good_words:\n",
    "            is_good += 1\n",
    "        if word in very_bad_words:\n",
    "            is_bad += 1\n",
    "    if is_good > is_bad:\n",
    "        return 'good'\n",
    "    elif is_bad > is_good:\n",
    "        return 'bad'\n",
    "    else:\n",
    "        return '?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тесты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала дособерем дополнительные 10 страниц ревью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('letterboxd_test.csv', 'w') as f:\n",
    "    header = ['movie', 'stars', 'review']\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_test():\n",
    "    with open('letterboxd_test.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for i in range(80, 90):\n",
    "            url = 'http://letterboxd.com/davidehrlich/films/reviews/page/'+str(i)+'/'\n",
    "            page_reviews = get_all_reviews_from_page(url)\n",
    "            write_reviews_from_page(page_reviews, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('letterboxd_test.csv')\n",
    "df_test = df_test.dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим тесты и посчитаем accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5892857142857143\n"
     ]
    }
   ],
   "source": [
    "success = 0\n",
    "fail = 0\n",
    "\n",
    "for index, row in df_test.iterrows():\n",
    "    movie = row['movie']\n",
    "    stars = row['stars']\n",
    "    review = row['review']\n",
    "    if stars > 7:\n",
    "        true_rating = 'good'\n",
    "    elif stars < 5:\n",
    "        true_rating = 'bad'\n",
    "    else:\n",
    "        true_rating = 'middle'\n",
    "        continue\n",
    "        \n",
    "    my_rating = decide_if_good(review, popular_very_good_words, popular_very_bad_words)\n",
    "    if my_rating == true_rating:\n",
    "        success +=1\n",
    "    else:\n",
    "        fail += 1\n",
    "        \n",
    "print('Accuracy: ', success/(success+fail))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предложения по улучшению: \n",
    "   1. Использовать не слова, а коллокации, чтобы разделить штуки типа 'was horrible' и 'was not horrible'\n",
    "   2. Посмотреть на длину хороших и плохих отзывов, на длину предложений в них, на использование смайликов и другие похожие вещи.\n",
    "   3. Сравнить количество восклицательных знаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
